{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6ff40-26e8-48d5-aac4-f0b9c18af798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from requests import get\n",
    "import zipfile, io\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from IPython import display\n",
    "import torch.nn.utils.parametrizations as param\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from model import make_model\n",
    "from dataset_generator import dataset_generator\n",
    "from utilities import generate_head_layer_ablations, FixedExamples, svd, PCA_plot, plot_attention_patterns, Relative_Angle_AfterFFN, Relative_Angle_AfterAttention, PCA_plot_different\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "plt.rcParams.update({\n",
    "        \"pgf.texsystem\": \"pdflatex\",\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": \"Helvetica\",\n",
    "        'pgf.rcfonts': False,\n",
    "    })\n",
    "\n",
    "plt.style.use('seaborn-v0_8-ticks')\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1912329",
   "metadata": {},
   "source": [
    "# Encoder only models analysis\n",
    "\n",
    "<font size = '3'> Below is how we dealt with the different kinds of ablations. It is a bit cumbersome, but hopefully you will manage.  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10509ef8-57f0-4e1c-b771-2afbefdac338",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ablation specification\n",
    "\n",
    "## Attention \n",
    "\n",
    "### The function generate_head_layer_ablations generates the set of all possible combinations of heads that can be ablated. \n",
    "# Pick one of these an use it for ab_head. Then specify with n_ab_head what layer you want to apply that ablation to. \n",
    "# The list ab_headrow is used in conjuction with M_apply. If M_apply is true, ab_headrow will be used and will ablate a specific row of the attention pattern.\n",
    "# Again n_ab_head determines what layer this ablation is applied to. \n",
    "\n",
    "n_ab_head = [] # Specifies of what layer we want to apply zero-ablation to.\n",
    "ab_head = [[1, 1], [1, 1]] # Specifies what head to ablate. This is a tensor of size (n, heads) with a 0 for those heads that you want to ablate, otherwise entries are one.\n",
    "ab_headrow = [] # Specifies what row within a head we want to apply zero-ablation to.\n",
    "M_apply = False # Specifies to whether to apply row-wise ablation or not. If True, use n_ab_head to set what layers you want the row-wise ablation to apply to.\n",
    "\n",
    "\n",
    "ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "# FFN\n",
    "\n",
    "List_Neurons = [] # List of neurons in the final layer you want to ablate.\n",
    "\n",
    "ablation_ffn = List_Neurons\n",
    "\n",
    "## Decoder \n",
    "\n",
    "n_ab_ffn = [] # Specifies which layer you want to ablate the FFN of. \n",
    "n_ab_att = [] # Specifies which layer you want to ablate the entire attention of. \n",
    "\n",
    "ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "ablations = [ablation_attention, ablation_ffn, ablation_decoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9606846",
   "metadata": {},
   "source": [
    "Data generation, outputs input data, target data and the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ead077",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f, target_f, stoi = dataset_generator(P_f = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3987998",
   "metadata": {},
   "source": [
    "# Load model\n",
    "\n",
    "<font size=\"3\">Using the parameters (n, s, w, p) you can load different models used in the text </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16defa8-3091-4a54-91d0-e7f0aa3521ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # Number of layers\n",
    "s = 0.2 # Train/test split\n",
    "w = 1.0 # weight decay\n",
    "p = 0 # Specifies which of the six models to consider. In this block used as a dummy variable, but can be specified later on. \n",
    "\n",
    "vocab = 12\n",
    "\n",
    "d_ff = 512\n",
    "d_model = 128\n",
    "heads = 2\n",
    "dropout = 0.1\n",
    "\n",
    "directory = 'n{!s}_s{!s}_w{!s}_dff512/'.format(n, s, w)\n",
    "mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "toLoad = directory + mdd\n",
    "\n",
    "model = make_model(vocab, N = n, d_model = d_model, d_ff = d_ff, h = heads, dropout = dropout, ablation_data = ablations)\n",
    "model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "mask = None\n",
    "\n",
    "# Data_out = []\n",
    "\n",
    "# for p in range(6):\n",
    "#     inputFile = 'DATA_n{!s}_s{!s}_w{!s}_{!s}.data'.format(n, s, w, p)\n",
    "#     inputFile = directory + inputFile\n",
    "#     fd = open(inputFile, 'rb')\n",
    "#     Data_out.append(pickle.load(fd))\n",
    "\n",
    "# T = len(Data_out[0][0])\n",
    "# print(len(Data_out[0])) # Number of timeseries per model: train/test loss, train/test accuracy, average attention patterns after each epoch, weight norm squared\n",
    "\n",
    "print('# of parameters =', sum(p.nelement() for p in model.parameters())) # number of parameters in total\n",
    "print('Training set size =', len(data_f)*s) \n",
    "\n",
    "Q = generate_head_layer_ablations(n, heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27216c5",
   "metadata": {},
   "source": [
    "Generate a set of examples with a given outcome and vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = FixedExamples(74, stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5732350",
   "metadata": {},
   "source": [
    "# Depending on what model you loaded, this generates \n",
    "# n = 2, s = 0.3, w = 0.2, p = 2 -> Fig. 3 and Fig. 4\n",
    "# n = 1, s = 0.3, w = 0.2, p = 0 -> Fig. 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d960733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This outputs:\n",
    "\n",
    "    1) PCA Analysis at output of Attention and MLP in each layer for the two leading axes. \n",
    "    \n",
    "    2) Attention pattern per task (determined by where carried ones are needed)\n",
    "\n",
    "    ### Keep in mind that SVD has a symmetry that flips the sign all singular left and right vectors. Which is why the figures below might be flipped compared to the ones in the text.\n",
    "\"\"\"\n",
    "\n",
    "### Specify model (out of six)\n",
    "\n",
    "p = 0\n",
    "\n",
    "### Ablation specification\n",
    "\n",
    "## Attention \n",
    "\n",
    "M_apply = False\n",
    "n_ab_head = []\n",
    "# ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]]\n",
    "# ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[],[]]]\n",
    "ab_headrow = []\n",
    "ab_head = Q[0]\n",
    "\n",
    "ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "## FFN\n",
    "\n",
    "List_Neurons = []\n",
    "\n",
    "ablation_ffn = List_Neurons\n",
    "\n",
    "## Decoder \n",
    "\n",
    "n_ab_ffn = []\n",
    "n_ab_att = []\n",
    "\n",
    "ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "ablations = [ablation_attention, ablation_ffn, ablation_decoder]\n",
    "\n",
    "ix = torch.randint(len(data_f), size = (20000,))\n",
    "data_ff = data_f[ix]\n",
    "target_ff = target_f[ix]\n",
    "\n",
    "mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "toLoad = directory + mdd\n",
    "\n",
    "model = make_model(vocab, N = n, d_model = 128, d_ff = d_ff, h = 2, dropout=0.1, ablation_data=ablations)\n",
    "model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "mask = None\n",
    "\n",
    "out = model(data_ff.to('cpu'), mask)\n",
    "\n",
    "Out_all = []\n",
    "for l in range(n):\n",
    "\n",
    "    Out_a = model.decoder.layers[l].out_a[:, :, :].detach().clone()\n",
    "    Out_a = Out_a - Out_a.mean(0, keepdim=True)\n",
    "    Out_all.append(Out_a)\n",
    "    Out_f = model.decoder.layers[l].out[:, :, :].detach().clone()\n",
    "    Out_f = Out_f - Out_f.mean(0, keepdim=True)\n",
    "    Out_all.append(Out_f)\n",
    "\n",
    "\n",
    "svd_full, positions, digit_ans_pos, digit_naive_ans_pos = svd(Out_all, data_ff, target_ff)\n",
    "\n",
    "PCA_plot(n=n, svd_full=svd_full, positions=positions, digit_ans_pos=digit_ans_pos, digit_naive_ans_pos=digit_naive_ans_pos)\n",
    "\n",
    "plot_attention_patterns(n=n, model=model, positions=positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36969b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This outputs:\n",
    "\n",
    "    Accuracy per position and for each of the six models\n",
    "\"\"\"\n",
    "\n",
    "a = torch.tensor([])\n",
    "\n",
    "for p in range(1):\n",
    "\n",
    "    ### Ablation specification\n",
    "\n",
    "    ## Attention \n",
    "\n",
    "    M_apply = False\n",
    "    n_ab_head = []  \n",
    "    # ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]]\n",
    "    # ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[],[]]]\n",
    "    ab_headrow = []\n",
    "    ab_head = Q[0]\n",
    "\n",
    "    ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "    ## FFN\n",
    "\n",
    "    List_Neurons = []\n",
    "\n",
    "    ablation_ffn = List_Neurons\n",
    "\n",
    "    ## Decoder \n",
    "\n",
    "    n_ab_ffn = []\n",
    "    n_ab_att = []\n",
    "\n",
    "    ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "    ablations = [ablation_attention, ablation_ffn, ablation_decoder]\n",
    "\n",
    "    ix = torch.randint(len(data_f), size = (20000,))\n",
    "    inputs = data_f[ix]\n",
    "    targets = target_f[ix]\n",
    "\n",
    "    mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "    toLoad = directory + mdd\n",
    "\n",
    "    model = make_model(vocab, N = n, d_model = 128, d_ff = d_ff, h = 2, dropout=0.1, ablation_data=ablations)\n",
    "    model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     for name, module in model.named_modules():\n",
    "    #         if isinstance(module, nn.Linear):\n",
    "    #             module.bias *= 0\n",
    "    \n",
    "    mask = None\n",
    "\n",
    "    out = model(inputs, mask)\n",
    "\n",
    "    a = torch.cat((a, (sum((torch.argmax(out[i, -3:, :].detach().to('cpu'), -1) == targets[i]).float() for i in range(len(inputs))) / len(inputs)).unsqueeze(0)), 0)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0448e69",
   "metadata": {},
   "source": [
    "# For the claim about squashing just above section 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This outputs:\n",
    "\n",
    "    Absolute value of cosine similarity between the hidden states for a given set of examples with fixed output \n",
    "    and computes the ratio between how much the overal similarity changes when going from attention output to MLP output\n",
    "\"\"\"\n",
    "\n",
    "### Ablation specification\n",
    "\n",
    "## Attention \n",
    "\n",
    "M_apply = False\n",
    "n_ab_head = []  \n",
    "# ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]]\n",
    "# ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[],[]]]\n",
    "ab_headrow = []\n",
    "ab_head = Q[0]\n",
    "\n",
    "ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "## FFN\n",
    "\n",
    "List_Neurons = []\n",
    "\n",
    "ablation_ffn = List_Neurons\n",
    "\n",
    "## Decoder \n",
    "\n",
    "n_ab_ffn = []\n",
    "n_ab_att = []\n",
    "\n",
    "ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "ablations = [ablation_attention, ablation_ffn, ablation_decoder]\n",
    "\n",
    "ratio = []\n",
    "\n",
    "for p in range(6):\n",
    "\n",
    "    mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "    toLoad = directory + mdd\n",
    "\n",
    "    model = make_model(vocab, N = n, d_model = 128, d_ff = d_ff, h = 2, dropout=0.1, ablation_data=ablations)\n",
    "    model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    angle_att = Relative_Angle_AfterAttention(model, examples=examples, layer=1, All=False)\n",
    "    angle_ffn = Relative_Angle_AfterFFN(model, examples=examples, layer=1, All =False)\n",
    "\n",
    "    max_ffn = angle_ffn[:, :, -3:].view(-1, 3).max(0)[0]\n",
    "    min_ffn = angle_ffn[:, :, -3:].view(-1, 3).min(0)[0]\n",
    "\n",
    "    max_att = angle_att[:, :, -3:].view(-1, 3).max(0)[0]\n",
    "    min_att = angle_att[:, :, -3:].view(-1, 3).min(0)[0]\n",
    "\n",
    "    ratio.append(((max_ffn - min_ffn) / (max_att - min_att)).tolist())\n",
    "\n",
    "ratio = torch.tensor(ratio)\n",
    "\n",
    "ratio, ratio.mean(0), ratio.std(0), ratio.max(0)\n",
    "\n",
    "# outputFile = directory + 'squashingATTtoFFN_layer1.data'\n",
    "# fw = open(outputFile, 'wb')\n",
    "# pickle.dump(ratio, fw)\n",
    "# fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29789949",
   "metadata": {},
   "source": [
    "# For ablating entire MLP\n",
    "# n = 2, s=0.3, w=0.2, p=range(6) -> Table 1 (right)\n",
    "# n = 3, s=0.3, w=0.2, p=range(6) -> Table 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This outputs:\n",
    "\n",
    "    Accuracy, non-corrected and corrected after ablating chosen part of network zero-ablated. \n",
    "    We correct answers manually to see whether the original ones where off by one either \n",
    "    by forgetting a carried one or adding one where it shouldnt have, this is the list vcorr. \n",
    "    This means: For non-carry over sums we subtract 1 from each position and when a carried one is needed we add it.  \n",
    "\"\"\"\n",
    "\n",
    "scores = torch.tensor([])\n",
    "\n",
    "for p in range(6):\n",
    "\n",
    "    mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "    toLoad = directory + mdd\n",
    "\n",
    "    scores_z = torch.tensor([])\n",
    "\n",
    "    for k in range(5):\n",
    "\n",
    "        ix = torch.randint(len(data_f), size = (20000,))\n",
    "        data_ff = data_f[ix]\n",
    "        target_ff = target_f[ix]\n",
    "\n",
    "        pos_nc = np.argwhere(sum((data_ff[:, j] + data_ff[:, j+4] >= 10) for j in range(3)) < 1)\n",
    "        pos_c1 = np.argwhere((data_ff[:, 1] + data_ff[:, 1+4] >= 10) & (sum((data_ff[:, j] + data_ff[:, j+4] >= 10).float() for j in np.delete(np.arange(3), 1)) < 1))\n",
    "        pos_c2 = np.argwhere((data_ff[:, 2] + data_ff[:, 2+4] >= 10) & (data_ff[:, 1] + data_ff[:, 5] < 9))\n",
    "        pos_2c = np.argwhere(sum((data_ff[:, j] + data_ff[:, j+4] >= 10) for j in range(3)) == 2)\n",
    "        pos_2cp = np.argwhere((data_ff[:, 1] + data_ff[:, 5] == 9) & (data_ff[:, 2] + data_ff[:, 6] >= 10))\n",
    "\n",
    "        tasks_src = [data_ff[pos_nc[0]], data_ff[pos_c1[0]], data_ff[pos_c2[0]], data_ff[pos_2c[0]], data_ff[pos_2cp[0]]]\n",
    "        tasks_tgt = [target_ff[pos_nc[0]], target_ff[pos_c1[0]], target_ff[pos_c2[0]], target_ff[pos_2c[0]], target_ff[pos_2cp[0]]]\n",
    "\n",
    "        vcorr = [torch.tensor([1, 1, 1]), torch.tensor([-1, 1, 1]), torch.tensor([1, -1, 1]), torch.tensor([-1, -1, 1]), torch.tensor([-1, -1, 1])]\n",
    "\n",
    "        inputs = tasks_src[k]\n",
    "        targets = tasks_tgt[k]\n",
    "        \n",
    "        scores_p = torch.tensor([])\n",
    "\n",
    "        for l in range(1):\n",
    "\n",
    "            ### Ablation specification\n",
    "\n",
    "            ## Attention \n",
    "\n",
    "            M_apply = False\n",
    "            n_ab_head = []\n",
    "            # ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]]\n",
    "            # ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[],[]]]\n",
    "            ab_headrow = []\n",
    "            ab_head = Q[0]\n",
    "\n",
    "            ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "            ## FFN\n",
    "\n",
    "            List_Neurons = []\n",
    "\n",
    "            ablation_ffn = List_Neurons\n",
    "\n",
    "            ## Decoder \n",
    "\n",
    "            n_ab_ffn = [1]\n",
    "            n_ab_att = []\n",
    "\n",
    "            ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "            ablations = [ablation_attention, ablation_ffn, ablation_decoder]\n",
    "\n",
    "            model = make_model(vocab, N = n, d_model = 128, d_ff = d_ff, h = 2, dropout=0.1, ablation_data=ablations)\n",
    "            model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "            model.eval()\n",
    "\n",
    "            mask = None\n",
    "            out = model(inputs, mask)\n",
    "\n",
    "            pre = torch.argmax(out[:, -3:, :].detach().to('cpu'), -1)\n",
    "\n",
    "            bp = sum((pre[i] == targets[i]).float() for i in range(len(inputs))) / len(inputs)\n",
    "\n",
    "            bcorr = sum(((pre[i] - vcorr[k]) % 10 == targets[i]).float() for i in range(len(inputs))) / len(inputs)\n",
    "\n",
    "            scores_p = torch.cat((scores_p, torch.cat((bp.unsqueeze(0), bcorr.unsqueeze(0)), 0)), 0)\n",
    "            \n",
    "        scores_z = torch.cat((scores_z, scores_p.unsqueeze(0)), 0)  \n",
    "\n",
    "    scores = torch.cat((scores, scores_z.unsqueeze(0)), 0)\n",
    "\n",
    "scores.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5e534",
   "metadata": {},
   "source": [
    "# For ablating decision heads\n",
    "# n = 2, s=0.3, w=0.2, p=range(6) -> Table 1 (left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This outputs:\n",
    "\n",
    "    Accuracy, non-corrected and corrected after ablating decision heads. \n",
    "    We correct answers manually to see whether the original ones where off by one either \n",
    "    by forgetting a carried one or adding one where it shouldnt have, this is the list vcorr. \n",
    "    This means: For non-carry over sums we subtract 1 from each position and when a carried one is needed we add it.  \n",
    "\"\"\"\n",
    "\n",
    "scores = torch.tensor([])\n",
    "\n",
    "for p in range(6):\n",
    "\n",
    "    mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "    toLoad = directory + mdd\n",
    "\n",
    "    scores_z = torch.tensor([])\n",
    "\n",
    "    for k in range(5):\n",
    "\n",
    "        ix = torch.randint(len(data_f), size = (20000,))\n",
    "        data_ff = data_f[ix]\n",
    "        target_ff = target_f[ix]\n",
    "\n",
    "        pos_nc = np.argwhere(sum((data_ff[:, j] + data_ff[:, j+4] >= 10) for j in range(3)) < 1)\n",
    "        pos_c1 = np.argwhere((data_ff[:, 1] + data_ff[:, 1+4] >= 10) & (sum((data_ff[:, j] + data_ff[:, j+4] >= 10).float() for j in np.delete(np.arange(3), 1)) < 1))\n",
    "        pos_c2 = np.argwhere((data_ff[:, 2] + data_ff[:, 2+4] >= 10) & (data_ff[:, 1] + data_ff[:, 5] < 9))\n",
    "        pos_2c = np.argwhere(sum((data_ff[:, j] + data_ff[:, j+4] >= 10) for j in range(3)) == 2)\n",
    "        pos_2cp = np.argwhere((data_ff[:, 1] + data_ff[:, 5] == 9) & (data_ff[:, 2] + data_ff[:, 6] >= 10))\n",
    "\n",
    "        tasks_src = [data_ff[pos_nc[0]], data_ff[pos_c1[0]], data_ff[pos_c2[0]], data_ff[pos_2c[0]], data_ff[pos_2cp[0]]]\n",
    "        tasks_tgt = [target_ff[pos_nc[0]], target_ff[pos_c1[0]], target_ff[pos_c2[0]], target_ff[pos_2c[0]], target_ff[pos_2cp[0]]]\n",
    "\n",
    "        vcorr = [torch.tensor([1, 1, 1]), torch.tensor([-1, 1, 1]), torch.tensor([1, -1, 1]), torch.tensor([-1, -1, 1]), torch.tensor([-1, -1, 1])]\n",
    "\n",
    "        inputs = tasks_src[k]\n",
    "        targets = tasks_tgt[k]\n",
    "        \n",
    "        scores_p = torch.tensor([])\n",
    "\n",
    "        for l in range(2):\n",
    "\n",
    "            ### Ablation specification\n",
    "\n",
    "            ## Attention \n",
    "\n",
    "            M_apply = False\n",
    "            n_ab_head = [1]\n",
    "            # ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]]\n",
    "            # ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[],[]]]\n",
    "            ab_headrow = []\n",
    "            ab_head = Q[l+1]\n",
    "\n",
    "            ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "            ## FFN\n",
    "\n",
    "            List_Neurons = []\n",
    "\n",
    "            ablation_ffn = List_Neurons\n",
    "\n",
    "            ## Decoder \n",
    "\n",
    "            n_ab_ffn = []\n",
    "            n_ab_att = []\n",
    "\n",
    "            ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "            ablations = [ablation_attention, ablation_ffn, ablation_decoder]\n",
    "\n",
    "            model = make_model(vocab, N = n, d_model = 128, d_ff = d_ff, h = 2, dropout=0.1, ablation_data=ablations)\n",
    "            model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "            model.eval()\n",
    "\n",
    "            mask = None\n",
    "            out = model(inputs, mask)\n",
    "\n",
    "            pre = torch.argmax(out[:, -3:, :].detach().to('cpu'), -1)\n",
    "\n",
    "            bp = sum((pre[i] == targets[i]).float() for i in range(len(inputs))) / len(inputs)\n",
    "\n",
    "            bcorr = sum(((pre[i] - vcorr[k]) % 10 == targets[i]).float() for i in range(len(inputs))) / len(inputs)\n",
    "\n",
    "            scores_p = torch.cat((scores_p, torch.cat((bp.unsqueeze(0), bcorr.unsqueeze(0)), 0)), 0)\n",
    "            \n",
    "        scores_z = torch.cat((scores_z, scores_p.unsqueeze(0)), 0)  \n",
    "\n",
    "    scores = torch.cat((scores, scores_z.unsqueeze(0)), 0)\n",
    "\n",
    "imp_att = torch.tensor([])\n",
    "imp_heads = [1, 0, 0, 0, 0, 1] # The decisions heads\n",
    "for j in range(6):\n",
    "    hj = 1 - imp_heads[j]\n",
    "    imp_att = torch.cat((imp_att, scores[j, :, (2*hj):(2*hj+2), :].unsqueeze(0)), 0)\n",
    "imp_att.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4cd0cd",
   "metadata": {},
   "source": [
    "# For the dissection claims in section 5.1 and appendix C.4\n",
    "# n = 2, s=0.3, w=0.2, p = 2 -> section 5.1\n",
    "# n = 2, s=0.1, w=0.2, p = 0, 2, 3 (can handle full ablation, p=1,4,5 can not) -> appendix C.4\n",
    "# n = 2, s=0.2, w=1.0, p = 0, d_ff = 512 -> Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"     \n",
    "    Dissecting the MLP and computing the accuracy after ablating a specific set of Neurons (List_Neurons)\n",
    "    We go through the data twice first to find the relevant Neurons and then to rerun the model with those \n",
    "    neurons zero-ablated. \n",
    "\n",
    "    This outputs: accuracy after ablation and the list of Neurons that were ablated.\n",
    "\"\"\"\n",
    "\n",
    "List_Neurons = []\n",
    "\n",
    "p = 3\n",
    "\n",
    "mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "toLoad = directory + mdd\n",
    "\n",
    "N_abl = []\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    ### Ablation specification\n",
    "\n",
    "    ## Attention \n",
    "\n",
    "    M_apply = False\n",
    "    n_ab_head = []\n",
    "    # ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]]\n",
    "    # ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[],[]]]\n",
    "    ab_headrow = []\n",
    "    ab_head = Q[0]\n",
    "\n",
    "    ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "    ## FFN\n",
    "\n",
    "    ablation_ffn = List_Neurons\n",
    "\n",
    "    ## Decoder \n",
    "\n",
    "    n_ab_ffn = []\n",
    "    n_ab_att = []\n",
    "\n",
    "    ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "    ablations = [ablation_attention, ablation_ffn, ablation_decoder]\n",
    "\n",
    "    model = make_model(vocab, N = n, d_model = 128, d_ff = d_ff, h = 2, dropout=0.1, ablation_data=ablations)\n",
    "    model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    ix = torch.randint(len(data_f), size = (20000,))\n",
    "    data_ff = data_f[ix]\n",
    "    target_ff = target_f[ix]\n",
    "\n",
    "    pos_nc = np.argwhere(sum((data_ff[:, j] + data_ff[:, j+4] >= 10) for j in range(3)) < 1)\n",
    "    pos_c1 = np.argwhere((data_ff[:, 1] + data_ff[:, 1+4] >= 10) & (sum((data_ff[:, j] + data_ff[:, j+4] >= 10).float() for j in np.delete(np.arange(3), 1)) < 1))\n",
    "    pos_c2 = np.argwhere((data_ff[:, 2] + data_ff[:, 2+4] >= 10) & (data_ff[:, 1] + data_ff[:, 5] < 9))\n",
    "    pos_2c = np.argwhere(sum((data_ff[:, j] + data_ff[:, j+4] >= 10) for j in range(3)) == 2)\n",
    "    pos_2cp = np.argwhere((data_ff[:, 1] + data_ff[:, 5] == 9) & (data_ff[:, 2] + data_ff[:, 6] >= 10))\n",
    "\n",
    "    tasks_src = [data_ff[pos_nc[0]], data_ff[pos_c1[0]], data_ff[pos_c2[0]], data_ff[pos_2c[0]], data_ff[pos_2cp[0]]]\n",
    "    tasks_tgt = [target_ff[pos_nc[0]], target_ff[pos_c1[0]], target_ff[pos_c2[0]], target_ff[pos_2c[0]], target_ff[pos_2cp[0]]]\n",
    "\n",
    "    vcorr = [torch.tensor([1, 1, 1]), torch.tensor([-1, 1, 1]), torch.tensor([1, -1, 1]), torch.tensor([-1, -1, 1]), torch.tensor([-1, -1, 1])]\n",
    "\n",
    "    a = torch.tensor([])\n",
    "    z_out = []\n",
    "    for k in range(len(tasks_src)):\n",
    "\n",
    "        inputs = tasks_src[k]\n",
    "        targets = tasks_tgt[k]\n",
    "\n",
    "        mask = None\n",
    "\n",
    "        out = model(inputs, mask)\n",
    "\n",
    "        ap = sum((torch.argmax(out[i, -3:, :].detach().to('cpu'), -1) == targets[i]).float() for i in range(len(inputs))) / len(inputs)\n",
    "\n",
    "        acorr = sum(((torch.argmax(\n",
    "                        out[i, -3:, :].detach().to('cpu'), -1) - vcorr[k]) % 10 == targets[i]).float() for i in range(len(inputs))) / len(inputs)\n",
    "\n",
    "        a = torch.cat((a, torch.cat((ap.unsqueeze(0), acorr.unsqueeze(0)), 0)), 0)\n",
    "\n",
    "        z = model.decoder.layers[n-1].ffn.out[:, -3:, :].mean(0).clone().detach()[0]\n",
    "        z_out.append(z)\n",
    "    Neur = []\n",
    "    for i in range(1, 5):  \n",
    "        zg = torch.argwhere(z_out[i] > z_out[0]).squeeze(-1)\n",
    "        for j in range(len(zg)):\n",
    "            if zg[j] not in Neur:\n",
    "                Neur.append(zg[j].item())\n",
    "    List_Neurons = Neur\n",
    "    N_abl.append(torch.tensor(List_Neurons))\n",
    "a, N_abl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ad1ae",
   "metadata": {},
   "source": [
    "# SVD Analysis for pre-activation weights\n",
    "# n=2, s=0.2, w=1.0, d_ff =512, p = 0, number_most_active_neurons = 256 -> Figure 13\n",
    "# n=2, s=0.3, w=0.2, p = 2, number_most_active_neurons = 64 -> Figure 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This generates a scatter plot of most active neurons for a given task and position.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "p = 3\n",
    "number_most_active_neurons = 64\n",
    "\n",
    "mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "toLoad = directory + mdd\n",
    "\n",
    "### Ablation specification\n",
    "\n",
    "## Attention \n",
    "\n",
    "M_apply = False\n",
    "n_ab_head = []\n",
    "# ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]]\n",
    "# ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[],[]]]\n",
    "ab_headrow = []\n",
    "ab_head = Q[0]\n",
    "\n",
    "ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "## FFN\n",
    "\n",
    "ablation_ffn = List_Neurons\n",
    "\n",
    "## Decoder \n",
    "\n",
    "n_ab_ffn = []\n",
    "n_ab_att = []\n",
    "\n",
    "ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "ablations = [ablation_attention, ablation_ffn, ablation_decoder]\n",
    "\n",
    "model = make_model(vocab, N = n, d_model = 128, d_ff = d_ff, h = 2, dropout=0.1, ablation_data=ablations)\n",
    "model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "MLP = model.decoder.layers[1].ffn.w1.weight.clone().detach()\n",
    "svd_mlp = torch.svd(MLP)\n",
    "\n",
    "\n",
    "ix = torch.randint(len(data_f), size = (20000,))\n",
    "data_ff = data_f[ix]\n",
    "target_ff = target_f[ix]\n",
    "\n",
    "digit_ans_pos = []\n",
    "for k in range(3):\n",
    "    ans_pp = []\n",
    "    for i in range(10):\n",
    "        ans_p = []\n",
    "        for j in range(len(target_ff)):\n",
    "            if target_ff[j, k] == i:\n",
    "                ans_p.append(j)\n",
    "        ans_pp.append(torch.tensor(ans_p))\n",
    "    digit_ans_pos.append(ans_pp)\n",
    "\n",
    "pos_nc = np.argwhere(sum((data_ff[:, j] + data_ff[:, j+4] >= 10) for j in range(3)) < 1)[0]\n",
    "pos_c1 = np.argwhere((data_ff[:, 1] + data_ff[:, 1+4] >= 10) & (sum((data_ff[:, j] + data_ff[:, j+4] >= 10).float() for j in np.delete(np.arange(3), 1)) < 1))[0]\n",
    "pos_c2 = np.argwhere((data_ff[:, 2] + data_ff[:, 2+4] >= 10) & (data_ff[:, 1] + data_ff[:, 5] < 9))[0]\n",
    "pos_2c = np.argwhere(sum((data_ff[:, j] + data_ff[:, j+4] >= 10) for j in range(3)) == 2)[0]\n",
    "pos_2cp = np.argwhere((data_ff[:, 1] + data_ff[:, 5] == 9) & (data_ff[:, 2] + data_ff[:, 6] >= 10))[0]\n",
    "\n",
    "positions = [pos_nc, pos_c1, pos_c2, pos_2c, pos_2cp]\n",
    "\n",
    "out = model(data_ff, None)\n",
    "\n",
    "z_out = []\n",
    "for k in range(3): \n",
    "    z_out_p = []\n",
    "    for i in range(10):\n",
    "        z = model.decoder.layers[1].ffn.out[digit_ans_pos[k][i], 7+k, :].clone().detach()\n",
    "        z_out_p.append(z)\n",
    "    z_out.append(z_out_p)\n",
    "\n",
    "z_out_n = []\n",
    "for k in range(3): \n",
    "    z_out_p = []\n",
    "    for i in range(len(positions)):\n",
    "        z = model.decoder.layers[1].ffn.out[positions[i], 7+k, :].clone().detach()\n",
    "        z_out_p.append(z)\n",
    "    z_out_n.append(z_out_p)\n",
    "\n",
    "def counter(a):\n",
    "    b = a.sort(descending=True)[0]\n",
    "    s = []\n",
    "    j = 1\n",
    "    for i in range(b.shape[0]-1):\n",
    "        if (b[i] > b[i+1]) and (i != b.shape[0] - 2):\n",
    "            s.append([b[i], j])\n",
    "            j = 1\n",
    "        elif i == b.shape[0] - 2:\n",
    "            s.append([b[i], j + 1])\n",
    "        elif b[i] == b[i+1]: \n",
    "            j += 1\n",
    "        \n",
    "    return torch.tensor(s)\n",
    "\n",
    "fig, ax = plt.subplots(3, 5, figsize=(20, 10))\n",
    "\n",
    "for k in range(3):\n",
    "    for j in range(len(positions)):\n",
    "        zz = torch.argwhere(z_out_n[k][j] != 0)[:, 1]\n",
    "\n",
    "        s_ = counter(zz)\n",
    "        sp = s_[s_[:, 1].sort(descending=True)[1]][:number_most_active_neurons, 0]\n",
    "\n",
    "        zzpos = list(set(sp.tolist()))\n",
    "        notzzpos = list(set(range(d_ff)) - set(zzpos))\n",
    "       \n",
    "        a, b = 0, 1\n",
    "\n",
    "        x = svd_mlp[0][notzzpos, a] * svd_mlp[1][a]\n",
    "        y = svd_mlp[0][notzzpos, b] * svd_mlp[1][b]\n",
    "\n",
    "        ax[2-k, j].scatter(x, y, alpha=0.3, color='blue')\n",
    "\n",
    "        x = svd_mlp[0][zzpos, a] * svd_mlp[1][a]\n",
    "        y = svd_mlp[0][zzpos, b] * svd_mlp[1][b]\n",
    "\n",
    "        ax[2-k, j].scatter(x, y, alpha=0.3, color='red')\n",
    "        ax[2-k, j].set_yticks([])\n",
    "        ax[2-k, j].set_xticks([])\n",
    "\n",
    "        # x = svd1[0][L, a] * svd1[1][a]\n",
    "        # y = svd1[0][L, b] * svd1[1][b]\n",
    "\n",
    "        # ax[j, k].scatter(x, y, alpha=0.3, color='black', marker='x')\n",
    "\n",
    "    ax[0, 0].set_title('$\\\\texttt{NC}$')\n",
    "    ax[0, 1].set_title('$\\\\texttt{C@1}$')\n",
    "    ax[0, 2].set_title('$\\\\texttt{C@2}$')\n",
    "    ax[0, 3].set_title('$\\\\texttt{C all}$')    \n",
    "    ax[0, 4].set_title('$\\\\texttt{C all con.}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6628b",
   "metadata": {},
   "source": [
    "# n=2, s=0.3, w=0.2, p=0 -> Figure 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This outputs:\n",
    "\n",
    "    1) PCA Analysis at output of Attention and MLP in each layer for the two leading axes. \n",
    "    \n",
    "    ### Keep in mind that SVD has a symmetry that flips the sign all singular left and right vectors. Which is why the figures below might be flipped compared to the ones in the text.\n",
    "\"\"\"\n",
    "\n",
    "### Specify model (out of six)\n",
    "\n",
    "p = 0\n",
    "\n",
    "### Ablation specification\n",
    "\n",
    "## Attention \n",
    "\n",
    "M_apply = False\n",
    "n_ab_head = []\n",
    "# ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]], [[0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]]\n",
    "# ab_headrow = [[[7, 8, 9], [7, 8, 9]], [[],[]]]\n",
    "ab_headrow = []\n",
    "ab_head = Q[0]\n",
    "\n",
    "ablation_attention = [M_apply, n_ab_head, ab_head, ab_headrow]\n",
    "\n",
    "## FFN\n",
    "\n",
    "List_Neurons = []\n",
    "\n",
    "ablation_ffn = List_Neurons\n",
    "\n",
    "## Decoder \n",
    "\n",
    "n_ab_ffn = []\n",
    "n_ab_att = []\n",
    "\n",
    "ablation_decoder = [n_ab_att, n_ab_ffn]\n",
    "\n",
    "ablations = [ablation_attention, ablation_ffn, ablation_decoder]\n",
    "\n",
    "ix = torch.randint(len(data_f), size = (20000,))\n",
    "data_ff = data_f[ix]\n",
    "target_ff = target_f[ix]\n",
    "\n",
    "mdd = 'model_n{!s}_s{!s}_w{!s}_{!s}'.format(n, s, w, p)\n",
    "toLoad = directory + mdd\n",
    "\n",
    "model = make_model(vocab, N = n, d_model = 128, d_ff = d_ff, h = 2, dropout=0.1, ablation_data=ablations)\n",
    "model.load_state_dict(torch.load(toLoad, map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "mask = None\n",
    "\n",
    "out = model(data_ff.to('cpu'), mask)\n",
    "\n",
    "Out_all = []\n",
    "for l in range(n):\n",
    "\n",
    "    Out_a = model.decoder.layers[l].out_a[:, :, :].detach().clone()\n",
    "    Out_a = Out_a - Out_a.mean(0, keepdim=True)\n",
    "    Out_all.append(Out_a)\n",
    "    Out_f = model.decoder.layers[l].out[:, :, :].detach().clone()\n",
    "    Out_f = Out_f - Out_f.mean(0, keepdim=True)\n",
    "    Out_all.append(Out_f)\n",
    "\n",
    "\n",
    "svd_full, positions, digit_ans_pos, digit_naive_ans_pos = svd(Out_all, data_ff, target_ff)\n",
    "\n",
    "PCA_plot_different(n=n, svd_full=svd_full, positions=positions, digit_ans_pos=digit_ans_pos, carry_or_non_carry_at_pos_8=True)\n",
    "PCA_plot_different(n=n, svd_full=svd_full, positions=positions, digit_ans_pos=digit_ans_pos, carry_or_non_carry_at_pos_8=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884ed83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4188f393c34fa2b8c99d7feb044de464e631de5d42645b8d328d986184b8407"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
